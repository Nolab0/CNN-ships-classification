{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Cette page doit être lancée sur Kaggle, depuis la compétition pour avoir accès aux données. Sinon vous devez récupérer les données séparément.","metadata":{}},{"cell_type":"markdown","source":"# IREN - Competition \"a la mano\"\n## Ships classification with custom neural network\n\n### Team:\n**Jean Fechter** - jean.fecther\n\n**Thibault Boutet** - thibault.boutet","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Resizing\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sn","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2023-05-28T17:43:41.55576Z","iopub.execute_input":"2023-05-28T17:43:41.556382Z","iopub.status.idle":"2023-05-28T17:43:41.847715Z","shell.execute_reply.started":"2023-05-28T17:43:41.556332Z","shell.execute_reply":"2023-05-28T17:43:41.846599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We define a seed to have reproducible results.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\nSEED = 0\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)","metadata":{"execution":{"iopub.status.busy":"2023-05-28T17:17:04.672873Z","iopub.execute_input":"2023-05-28T17:17:04.673897Z","iopub.status.idle":"2023-05-28T17:17:04.6978Z","shell.execute_reply.started":"2023-05-28T17:17:04.673814Z","shell.execute_reply":"2023-05-28T17:17:04.696344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data loading\nLet's load, display and get some informations on the data which are in the kaggle input.","metadata":{"execution":{"iopub.status.busy":"2023-05-28T08:34:33.025451Z","iopub.execute_input":"2023-05-28T08:34:33.026328Z","iopub.status.idle":"2023-05-28T08:34:33.057377Z","shell.execute_reply.started":"2023-05-28T08:34:33.026286Z","shell.execute_reply":"2023-05-28T08:34:33.054993Z"}}},{"cell_type":"code","source":"dataset = tf.keras.utils.image_dataset_from_directory(\n    \"/kaggle/input/navires-2023-la-mano/ships16x24/ships_16x24_10cat/data\",\n    labels='inferred',\n    label_mode=\"categorical\",\n    image_size=(16, 24)\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-28T17:17:04.705197Z","iopub.execute_input":"2023-05-28T17:17:04.706181Z","iopub.status.idle":"2023-05-28T17:17:15.988738Z","shell.execute_reply.started":"2023-05-28T17:17:04.706138Z","shell.execute_reply":"2023-05-28T17:17:15.987608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the class labels from the dataset\nclass_labels = dataset.class_names\nprint(f\"Number of classes: {len(class_labels)}\")\nprint(class_labels)","metadata":{"execution":{"iopub.status.busy":"2023-05-28T17:17:15.990535Z","iopub.execute_input":"2023-05-28T17:17:15.991027Z","iopub.status.idle":"2023-05-28T17:17:15.998128Z","shell.execute_reply.started":"2023-05-28T17:17:15.990985Z","shell.execute_reply":"2023-05-28T17:17:15.99705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the first image for each class\nplt.figure(figsize=(15, 15))\nfor images, labels in dataset.take(1):\n    for i in range(10):\n        ax = plt.subplot(3, 4, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(class_labels[i])\n        plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2023-05-28T17:17:16.002324Z","iopub.execute_input":"2023-05-28T17:17:16.003513Z","iopub.status.idle":"2023-05-28T17:17:16.568173Z","shell.execute_reply.started":"2023-05-28T17:17:16.003468Z","shell.execute_reply":"2023-05-28T17:17:16.567057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Although it's impossible for a human to classify those ships due to the low resolution of the images, let's see how a neural network handles this task.\n\n\n## Data pre-processing\n\n### Data augmentation\nData augmentation is a technique that expands a training dataset by applying transformations like rotations, translations, and flipping to the existing data. It improves model generalization and robustness by exposing it to a wider range of variations. This reduces overfitting and enhances pattern recognition.\n\nAfter testing different configuration of data augmentation, we have chosen to apply:\n* Rescaling\n* Horizontal flip\n\nThe other data augmentation techniques such as rotation or translation increase a lot the training time for unsignificative results.\n### Train/Validation split\nWe will split the dataset into **two sets**:\n* Train set (**80%** of the dataset): Part of the dataset used to train the model\n* Validation set (**20%** of the dataset): Part of the dataset used to test the model's accuracy during the training","metadata":{}},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rescale=1./255,\n    validation_split=0.2,\n    horizontal_flip=True,\n)\n\ntrain_generator = train_datagen.flow_from_directory(\n    '/kaggle/input/navires-2023-la-mano/ships16x24/ships_16x24_10cat/data',\n    target_size=(16, 24),\n    batch_size=32,\n    class_mode='categorical',\n    seed=SEED,\n    subset='training',\n)\n\nvalidation_generator = train_datagen.flow_from_directory(\n    '/kaggle/input/navires-2023-la-mano/ships16x24/ships_16x24_10cat/data',\n    target_size=(16, 24),\n    batch_size=32,\n    class_mode='categorical',\n    seed=SEED,\n    subset='validation',\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-28T17:17:16.56962Z","iopub.execute_input":"2023-05-28T17:17:16.570455Z","iopub.status.idle":"2023-05-28T17:17:18.226322Z","shell.execute_reply.started":"2023-05-28T17:17:16.570407Z","shell.execute_reply":"2023-05-28T17:17:18.225208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Creation\n\nNow that the data is loaded, let's create our custom model.\nWe are going to need different layers in order to make it as efficient as possible :\n* Resizing : changes the size of the image. In our case, we double it as part of the data augmentation\n* Conv2D : we use a 3x3 kernel and relu activation function to extract the features from the image\n* MaxPooling2D : downsamples the input by selecting the maximum value within each local region to extract the most important features\n* Dropout : randomly deactivates certain neurons, preventing overfitting\n* BatchNormalization : normalizes the batch (mean = 0, standard deviation = 1) to make the network converge faster\n* Flatten : reshapes the output into a 1D array\n* Dense : fully connected (each neuron is connected to every neuron from the previous layer)\n\nAfter testing different optimizers, we chose to use **Adam** as it gave the best results. We modified the learning rate to start at 0.01 (see RecudeLrOnPlateau bellow for more explainations)","metadata":{}},{"cell_type":"code","source":"\nmodel = tf.keras.models.Sequential([\n    Resizing(32, 48, interpolation=\"bicubic\"),\n    Conv2D(64, (3, 3), padding='same', activation='relu', input_shape=(16, 24, 3)),\n    MaxPooling2D((2, 2)),\n    Dropout(0.4),\n    BatchNormalization(),\n    Conv2D(128, (3, 3), padding='same', activation='relu'),\n    Conv2D(128, (3, 3), padding='same', activation='relu'),\n    MaxPooling2D((2, 2)),\n    BatchNormalization(),\n    Conv2D(256, (3, 3), padding='same', activation='relu'),\n    Conv2D(256, (3, 3), padding='same', activation='relu'),\n    MaxPooling2D((2, 2)),\n    Dropout(0.4),\n    BatchNormalization(),\n    Flatten(),\n    Dense(1024, activation='relu'),\n    Dropout(0.5),\n    Dense(10, activation='softmax')\n])\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(lr=0.01),\n          loss='categorical_crossentropy',\n          metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-05-28T17:17:18.228125Z","iopub.execute_input":"2023-05-28T17:17:18.228788Z","iopub.status.idle":"2023-05-28T17:17:18.280024Z","shell.execute_reply.started":"2023-05-28T17:17:18.228746Z","shell.execute_reply":"2023-05-28T17:17:18.279014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Number of layers : \", len(model.layers))","metadata":{"execution":{"iopub.status.busy":"2023-05-28T17:17:18.281868Z","iopub.execute_input":"2023-05-28T17:17:18.282264Z","iopub.status.idle":"2023-05-28T17:17:18.291764Z","shell.execute_reply.started":"2023-05-28T17:17:18.28222Z","shell.execute_reply":"2023-05-28T17:17:18.290392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model training\nNow that our model is defined, we need to train it on our data.\nTo improve the convergence of the model, we will use **callbacks**.\n\n### Callbacks\nA callback is a function that performs tasks during the training of a model. We will use an **EarlyStopping** callback and an **ReduceLrOnPlateau** callback.\n* EarlyStopping: This callback allows to stop the training of the model when the loss or the accuracy does not improve after a certain number of epoch. We have chosen to stop the training when the accuracy does not improve after 5 consecutive epochs\n* RecudeLrOnPlateau: This callback is used to adjust dynamically the learning rate during the training. We have chosen to wait 1 epoch of no improvment to reduce the learning rate by a 0.2 factor. Note that the learning rate can't be smaller than 1e-4","metadata":{}},{"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True, verbose=2)\n\nlr_callback = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=1, min_lr=0.0001)\n\nmodel_history = model.fit(train_generator, epochs=50, validation_data=validation_generator, callbacks=[early_stopping, lr_callback])","metadata":{"execution":{"iopub.status.busy":"2023-05-28T17:17:18.293313Z","iopub.execute_input":"2023-05-28T17:17:18.2959Z","iopub.status.idle":"2023-05-28T17:41:53.182925Z","shell.execute_reply.started":"2023-05-28T17:17:18.29586Z","shell.execute_reply":"2023-05-28T17:41:53.181669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Results analysis\n### Curves\nOnce the training is finished, we want to plot the **loss** and the **accuracy** on the training and validation sets.\nThese two indicators measure the performance of the model.\nHere are the formula to compute these indicators:\n* Accuracy = Number of correct predictions / Total number of predictions\n* Loss (Cross-Entropy Loss) = -Σ(y_actual * log(y_pred))","metadata":{}},{"cell_type":"code","source":"#Loss\nplt.plot(model_history.history['loss'], label='Train')\nplt.plot(model_history.history['val_loss'], label='Validation')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.title('Model Loss')\nplt.legend(loc='upper right')","metadata":{"execution":{"iopub.status.busy":"2023-05-28T17:41:53.184468Z","iopub.execute_input":"2023-05-28T17:41:53.18566Z","iopub.status.idle":"2023-05-28T17:41:59.019828Z","shell.execute_reply.started":"2023-05-28T17:41:53.185595Z","shell.execute_reply":"2023-05-28T17:41:59.018708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Accuracy\nplt.plot(model_history.history['accuracy'], label='Train')\nplt.plot(model_history.history['val_accuracy'], label='Validation')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.title('Model Accuracy')\nplt.legend(loc='upper right')","metadata":{"execution":{"iopub.status.busy":"2023-05-28T17:41:59.021563Z","iopub.execute_input":"2023-05-28T17:41:59.022273Z","iopub.status.idle":"2023-05-28T17:41:59.286548Z","shell.execute_reply.started":"2023-05-28T17:41:59.022224Z","shell.execute_reply":"2023-05-28T17:41:59.285458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The ideal scenario for both graphs would be if both curves on each graph followed the exact same variations.<br>\nWe can observe that until epoch 12, they do.<br>After that, the accuracy and loss on the validation set starts to stabilize, improving little by little.<br>Because the validation curve for the loss never increases significantly, and the validation curve for the acuracy never decreases significantly, after epoch 12, we know that our model is **not overfitting**.","metadata":{}},{"cell_type":"markdown","source":"### Confusion matrix\nA confusion matrix is a table that evaluates a classification model's performance by comparing predicted and actual values for each class. It provides key metrics like accuracy, precision, and recall, helping to assess the model's strengths and weaknesses in classifying different categories.\n\nIn order to build a confusion matrix, we need to have a set to make a prediction on with our model. Let's take the validation set to do the prediction and construct the matrix.","metadata":{}},{"cell_type":"code","source":"Y_pred = model.predict(validation_generator)\ny_pred = np.argmax(Y_pred, axis=1)\ncm = confusion_matrix(validation_generator.classes, y_pred)\nplt.figure(figsize=(10, 8))\nsn.heatmap(cm, annot=True, cmap='Blues', fmt='d', xticklabels=class_labels, yticklabels=class_labels)\nplt.xlabel('Predicted labels')\nplt.ylabel('True labels')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-28T18:06:34.927899Z","iopub.execute_input":"2023-05-28T18:06:34.928919Z","iopub.status.idle":"2023-05-28T18:06:42.523551Z","shell.execute_reply.started":"2023-05-28T18:06:34.928875Z","shell.execute_reply":"2023-05-28T18:06:42.522469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We notice that among other things, our model struggles to differentiate containerships, cruisers and destroyers.","metadata":{}},{"cell_type":"markdown","source":"## Submission\nThis part is responsible of the loading and prediction of the given test data by the network.\n\nAt the end, a *.csv* file is generated with the network's predictions.","metadata":{"execution":{"iopub.execute_input":"2022-05-02T16:53:05.081503Z","iopub.status.busy":"2022-05-02T16:53:05.081093Z","iopub.status.idle":"2022-05-02T16:53:05.087029Z","shell.execute_reply":"2022-05-02T16:53:05.085976Z","shell.execute_reply.started":"2022-05-02T16:53:05.081444Z"}}},{"cell_type":"code","source":"X_test = np.load('/kaggle/input/navires-2023-la-mano/test.npy', allow_pickle=True)\nX_test = X_test.astype('float32') / 255","metadata":{"execution":{"iopub.status.busy":"2023-05-28T17:44:27.730284Z","iopub.execute_input":"2023-05-28T17:44:27.731315Z","iopub.status.idle":"2023-05-28T17:44:27.911228Z","shell.execute_reply.started":"2023-05-28T17:44:27.731269Z","shell.execute_reply":"2023-05-28T17:44:27.909906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res = model.predict(X_test).argmax(axis=1)\ndf = pd.DataFrame({\"Category\":res})\ndf.to_csv(\"reco_nav.csv\", index_label=\"Id\")","metadata":{"execution":{"iopub.status.busy":"2023-05-28T17:47:47.442315Z","iopub.execute_input":"2023-05-28T17:47:47.4428Z","iopub.status.idle":"2023-05-28T17:47:47.950418Z","shell.execute_reply.started":"2023-05-28T17:47:47.442758Z","shell.execute_reply":"2023-05-28T17:47:47.949349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.chdir(r'/kaggle/working')\nfrom IPython.display import FileLink\nFileLink(r'reco_nav.csv')","metadata":{"execution":{"iopub.status.busy":"2023-05-28T17:47:58.863323Z","iopub.execute_input":"2023-05-28T17:47:58.864114Z","iopub.status.idle":"2023-05-28T17:47:58.875353Z","shell.execute_reply.started":"2023-05-28T17:47:58.86407Z","shell.execute_reply":"2023-05-28T17:47:58.873941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusion\nIn this notebook, we have used a **custom hand-made model** to classify ships into 10 classes.\n<br>\nWe had to try many different elements and strategies in order to find the best combination of pre-processing and layers for our model.<br>\nOur network reaches **over 80% of accurate predictions** on the given test data.","metadata":{}},{"cell_type":"markdown","source":"##### ","metadata":{}}]}